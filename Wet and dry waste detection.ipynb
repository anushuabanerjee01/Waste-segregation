{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount drive onto Google colab, to load dataset.\n",
    "Dataset contains 800 images and 800 annotations of wet and dry waste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation instructions:\n",
    "\n",
    "Run these commands:\n",
    "\n",
    "git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "\n",
    "cd Monk_Object_Detection/5_pytorch_retinanet/installation\n",
    "\n",
    "Select the right requirements file and run\n",
    "\n",
    "cat requirements_cuda.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab use the command below\n",
    "! cd Monk_Object_Detection/5_pytorch_retinanet/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
    "\n",
    "# For Local systems and cloud select the other file\n",
    "#! cd Monk_Object_Detection/5_pytorch_retinanet/installation && cat requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotations are in Pascal VOC format.\n",
    "\n",
    "They need to be converted to COCO type via Monk type format.\n",
    "\n",
    "Step 1:To convert from VOC to Monk type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"Waste_Dataset/\";\n",
    "img_dir = \"Images_merged/\";\n",
    "anno_dir = \"Annotations_merged/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(root_dir + anno_dir);\n",
    " print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];\n",
    "for i in tqdm(range(len(files))):\n",
    "    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n",
    "    fname = anno[\"filename\"];\n",
    "    label_str = \"\";\n",
    "    if(type(anno[\"object\"]) == list ):\n",
    "        for j in range(len(anno[\"object\"])):\n",
    "            obj = dict(anno[\"object\"][j]);\n",
    "            label = anno[\"object\"][j][\"name\"];\n",
    "            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n",
    "            x1 = bbox[\"xmin\"];\n",
    "            y1 = bbox[\"ymin\"];\n",
    "            x2 = bbox[\"xmax\"];\n",
    "            y2 = bbox[\"ymax\"];\n",
    "            if(j == len(anno[\"object\"])-1):\n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "            else:        \n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "    else:\n",
    "        obj = dict(anno[\"object\"]);\n",
    "        label = anno[\"object\"][\"name\"];\n",
    "        bbox = dict(anno[\"object\"][\"bndbox\"])\n",
    "        x1 = bbox[\"xmin\"];\n",
    "        y1 = bbox[\"ymin\"];\n",
    "        x2 = bbox[\"xmax\"];\n",
    "        y2 = bbox[\"ymax\"];\n",
    "        \n",
    "        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "    \n",
    "    \n",
    "    combined.append([fname, label_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Monk type to COCO type format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"Waste_Dataset/\";\n",
    "img_dir = \"Images_merged/\";\n",
    "anno_file = \"train_labels.csv\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \" \";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    print(image_in_path)\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use already trained model to train for detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.path.append(\"Monk_Object_Detection/5_pytorch_retinanet/lib/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_detector import Detector\n",
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./\";\n",
    "coco_dir=\"Waste_Dataset\";\n",
    "img_dir = \"./\";\n",
    "set_dir = \"Images_merged\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train_Dataset(root_dir,coco_dir, img_dir, set_dir, batch_size=2, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.system_dict[\"local\"][\"dataset_train\"].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model used: resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model(model_name=\"resnet50\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Set_Hyperparams(lr=0.0001, print_interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training number of epochs used is 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train(num_epochs=8, output_model_name=\"final_model.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/5_pytorch_retinanet/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gtf.Model(model_path=\"final_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Waste_Dataset/annotations/classes.txt\", 'r');\n",
    "class_list = f.readlines();\n",
    "f.close();\n",
    "for i in range(len(class_list)):\n",
    "    class_list[i] = class_list[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test on sample images for detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/plastic251.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/plastic258.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/plastic249.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/plastic236.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/O_41.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/O_37.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Waste_Dataset/Images_merged/image107.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
